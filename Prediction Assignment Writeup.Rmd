---
title: "Practical Machine Learning: Prediction Assignment Writeup"
output: html_document
---

### Objective
The goal of this project is to build a model that predicts the manner individuals perform an excercise correctly.  New devices, i.e. Jawbone Up, Nike Fuelband, and Fitbit, make it possible to collect large amount of information. Generally, studies have focused on quantifying how much activity, rather than quantify how well the activity was excised. This project write-up outlines the process to build a machine learing model that predicts and classifies how well individuals perform the activity.

Data was provided from Groupware@LES: Human Activity Recognition.  More information is available from the website here: <http://groupware.les.inf.puc-rio.br/har> (see the section on the Weight Lifting Exercise Dataset). 

### Viewing the Data
First load the caret package that will be used. Load the data and view the summary. 
```{r}
library(caret)

rawTrain <- read.csv("./data/pml-training.csv", header = TRUE)
rawTest <-read.csv("./data/pml-testing.csv", header = TRUE)

summary(rawTrain)
```

### Preparing the Data
The training data set seems to have NA and Divide by Zero errors.  The data must be reload and adjusted for missing data.  Remove all predictors where there are missing data (NA exist).

```{r}
rawTrain <-read.csv("./data/pml-training.csv", header = TRUE, na.strings = c("NA", "#DIV/0!"))
rawTrain <- rawTrain[ , colSums(is.na(rawTrain)) == 0]
```

With many columns removed, check for near zero variance predictors and also remove them.

```{r}
nzv <- nearZeroVar(rawTrain, saveMetrics = TRUE)
nzv
rawTrain <- rawTrain[,rownames(nzv[!nzv$nzv,])]
```

Some of the columns appears to be be descriptive columns, and they can be removed (X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window). 

```{r}
rawTrain <- rawTrain[, -c(1:6)]
```

### Cross Validation, Random Forest Model
Finally, with clean data to work on and a total of 52 predictors (excluding "classe").  So, now set the seed and use cross validation by partitioning the data into training set and testing set (not the actual Test data).  Data is split 70:30, Training vs Testing.

```{r}
library(randomForest)
set.seed(66688)
inTrain <- createDataPartition(y = rawTrain$classe, p = 0.7, list = FALSE)
training <- rawTrain[inTrain,]
testing <- rawTrain[-inTrain,]
```

Based on successful implementations using Random Forest on Kaggle, the initial model will use randomforest package in R.  Once completed, the model display the final result.  Model is setup with 5 folds.  10 folds took a long time to run.

```{r}
trCon <- trainControl(method = "cv", number = 5, allowParallel = TRUE, verbose = TRUE)
modFit <- train(classe ~., data = training, method = "rf", trControl = trCon)
```
```{r, echo=FALSE }
modFit$finalModel
```

Result look promising, so using this fitted model, run on the testing set and show the confusionMatrix.

```{r}
pred <- predict(modFit, newdata = testing)
confusionMatrix(pred, testing$classe)
```

### Model Results
The model shows a very good accuracy at 99.18% at 95% Confidence Interval, and a Kappa of 0.9897. These results will likely be better than the expected result when running against the actual Test data. As a sanity check, to compare, below models used rpart and gbm on the same training and testing data.

```{r}
library(rpart)
library(gbm)
rpartmod <- train(classe ~., data = training, method = "rpart")
gbmmod <- train(classe ~., data = training, method = "gbm", trControl = trCon, verbose = FALSE)

predrpart <- predict(rpartmod, newdata = testing)
confusionMatrix(predrpart, testing$classe)
predgbm <- predict(gbmmod, newdata = testing)
confusionMatrix(predgbm, testing$classe)
```

Randon Forest model appears to perform better than trees and boosting. RF will be used to on the Test data.

### Applying model to Test data.
Using the Random Forest Model, modFit, predict the Test data.

```{r}
TestResult <- predict(modFit, newdata = rawTest)
TestResult
```

Using the following, generate the answer files for each problem.  All results were correct.  :)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(TestResult)



